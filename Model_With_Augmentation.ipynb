{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6293f9d4",
   "metadata": {},
   "source": [
    "## Preprocessing Sction.\n",
    "This section is inspired by the preprocessing of another computer scientist who was using the same dataset to do their own experiments on it.\n",
    "\n",
    "Link to their repositry: [TanushGoel / Breast-Histopathology-IDC-Classification](https://github.com/TanushGoel/Breast-Histopathology-IDC-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca5493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing that the machine recognizes the GPU\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a2fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from os.path import isfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import utils\n",
    "import itertools\n",
    "import shutil\n",
    "np.random.seed(42)\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f3bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1659a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new all image dir folder \n",
    "all_images_dir = 'all_images_dir_AUG'\n",
    "os.chdir('./breast-histopathology-images/')\n",
    "if(os.path.exists(f'./breast-histopathology-images/{all_images_dir}')):\n",
    "    os.mkdir(all_images_dir)\n",
    "\n",
    "    # Create Positive subdirectory within all images\n",
    "    os.mkdir('all_images_dir_AUG/1')\n",
    "    os.mkdir('all_images_dir_AUG/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5a8810",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_images_dir/1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./breast-histopathology-images/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# copies all images from their seperate folders into the same \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# folder called all_images_dir\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# '0'\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# '1'\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m all_pos_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_images_dir/1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m all_neg_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_images_dir/0\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_pos_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m all_neg_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_images_dir/1'"
     ]
    }
   ],
   "source": [
    "\n",
    "# to get rid of changing the directory more than once\n",
    "# os.chdir(current_dir)\n",
    "\n",
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "# all_images_dir = 'all_images_dir_AUG'\n",
    "# os.chdir('./breast-histopathology-images/')\n",
    "# copies all images from their seperate folders into the same \n",
    "# folder called all_images_dir\n",
    "\n",
    "\n",
    "# create a list of all patient id's\n",
    "# each patient id folder has 2 sub folders --> folder 0 and folder 1\n",
    "\n",
    "# Example:\n",
    "    # '10285'\n",
    "        # '0'\n",
    "        # '1'\n",
    "        \n",
    "all_pos_len = len(os.listdir(f'{all_images_dir}/1'))\n",
    "all_neg_len = len(os.listdir(f'{all_images_dir}/0'))\n",
    "\n",
    "\n",
    "if all_pos_len == 0 or all_neg_len == 0:\n",
    "    cur_dir = os.getcwd()\n",
    "    patient_list = os.listdir(cur_dir)\n",
    "\n",
    "    for patient in patient_list:\n",
    "\n",
    "      try:\n",
    "\n",
    "        path_0 = str(patient) + '/0'\n",
    "        path_1 = str(patient) + '/1'\n",
    "\n",
    "        # create a list of all files in folder 0\n",
    "        file_list_0 = os.listdir(path_0)\n",
    "        # create a list of list all file in folder 1\n",
    "        file_list_1 = os.listdir(path_1)\n",
    "\n",
    "        # move the 0 images to all_images_dir\n",
    "        for fname in file_list_0:\n",
    "\n",
    "            # source path to image\n",
    "            src = os.path.join(path_0, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(all_images_dir, '0', fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        # move the 1 images to all_images_dir\n",
    "        for fname in file_list_1:\n",
    "\n",
    "            # source path to image\n",
    "            src = os.path.join(path_1, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(all_images_dir, '1', fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "      except:\n",
    "         print(patient, 'cannot be copied into proper folder')\n",
    "else:\n",
    "    print(\"Data already exists. Skipped copying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many images are in each folder, to make sure we have correct data\n",
    "print('Total:', all_pos_len + all_neg_len)\n",
    "print('Positive:', all_pos_len)\n",
    "print('Negative:', all_neg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "# Create a dataframe containing all the information\n",
    "\n",
    "image_list_1 = os.listdir(f'{all_images_dir}/1')\n",
    "df_data_1 = pd.DataFrame(image_list_1, columns=['image_id'])\n",
    "\n",
    "image_list_0 = os.listdir(f'{all_images_dir}/0')\n",
    "df_data_0 = pd.DataFrame(image_list_0, columns=['image_id'])\n",
    "\n",
    "df_data = pd.concat([df_data_1, df_data_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating that the data now exists in the dataframe\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9943fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "# Define Helper Functions\n",
    "\n",
    "# Each file name has this format:\n",
    "# '14211_idx5_x2401_y1301_class1.png'\n",
    "\n",
    "def extract_patient_id(x):\n",
    "    # split into a list\n",
    "    a = x.split('_')\n",
    "    # the id is the first index in the list\n",
    "    patient_id = a[0]\n",
    "    \n",
    "    return patient_id\n",
    "\n",
    "def extract_target(x):\n",
    "    # split into a list\n",
    "    a = x.split('_')\n",
    "    # the target is part of the string in index 4\n",
    "    b = a[4]\n",
    "    # the ytarget i.e. 1 or 2 is the 5th index of the string --> class1\n",
    "    target = b[5]\n",
    "    \n",
    "    return target\n",
    "\n",
    "# extract the patient id\n",
    "\n",
    "# create a new column called 'patient_id'\n",
    "df_data['patient_id'] = df_data['image_id'].apply(extract_patient_id)\n",
    "# create a new column called 'target'\n",
    "df_data['target'] = df_data['image_id'].apply(extract_target)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96a3ed",
   "metadata": {},
   "source": [
    "### The class distribution of the dataset.\n",
    "There are more negative cases than the positive ones. This makes the dataset imbalanced since the nature of the problem doesn't require that the number of negative cases to be more or less than the positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250329ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the class distribution of the dataset, We find that the negative is way more than the positives.\n",
    "sns.countplot(x=df_data.target).set_title(\"Class Distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b910fe1",
   "metadata": {},
   "source": [
    "# Train / Test / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba46e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_data['target']\n",
    "\n",
    "_, df_test = train_test_split(df_data, test_size=0.03603, random_state=42, stratify=y)\n",
    "\n",
    "_, df_val = train_test_split(df_data, test_size=0.0036025, random_state=42, stratify=y)\n",
    "\n",
    "print('Valid:', df_val.shape[0])\n",
    "print('Test:', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_val['target']).set_title('Valid Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad599ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_test['target']).set_title('Test Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b968cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved the speed of the identification through using a dictionary... Dramatically.\n",
    "val_dict = df_val.set_index('image_id').T.to_dict('list')\n",
    "test_dict = df_test.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "def identify_train_val_and_test_rows(x):\n",
    "    if str(x) in val_dict:\n",
    "        return 'val'\n",
    "    elif str(x) in test_dict:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_data['train_or_val_or_test'] = df_data['image_id']\n",
    "# apply the function to this new column\n",
    "df_data['train_or_val_or_test'] = df_data['train_or_val_or_test'].apply(identify_train_val_and_test_rows)\n",
    "   \n",
    "# filter out train rows\n",
    "df_train = df_data[df_data['train_or_val_or_test'] == 'train']\n",
    "\n",
    "print('Train:', len(df_train))\n",
    "print('Valid:', len(df_val))\n",
    "print('Test:', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_train['target']).set_title('Train Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image_id as the index in df_data\n",
    "df_data.set_index('image_id', inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Train, Valid, and Test Folders\n",
    "\n",
    "\n",
    "# Create folders within the train, valid, and test folders\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# train_dir\n",
    "train_dir = os.path.join('train_dir_AUG')\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    # create new folders inside train_dir\n",
    "    os.mkdir(os.path.join(train_dir, '1'))\n",
    "    os.mkdir(os.path.join(train_dir, '0'))\n",
    "    \n",
    "# val_dir\n",
    "val_dir = os.path.join('val_dir_AUC')\n",
    "if not os.path.isdir(val_dir):\n",
    "    os.mkdir(val_dir)\n",
    "    # Create new folders inside val_dir\n",
    "    os.mkdir(os.path.join(val_dir, '1'))\n",
    "    os.mkdir(os.path.join(val_dir, '0'))\n",
    "\n",
    "# test_dir\n",
    "test_dir = os.path.join('test_dir_AUG')\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    # Create new folders inside test_dir\n",
    "    os.mkdir(os.path.join(test_dir, '1'))\n",
    "    os.mkdir(os.path.join(test_dir, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfering the data from the starting directory to the training directory\n",
    "if len(os.listdir(train_dir)) == 0:\n",
    "    # Get a dict of train, val, and test images\n",
    "    train_dict = df_train.set_index('image_id').T.to_dict('list')\n",
    "    test_dict = df_test.set_index('image_id').T.to_dict('list')\n",
    "    val_dict = df_val.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "    # Transfer the train images\n",
    "    for image in train_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # Transfer the val images\n",
    "    for image in val_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # Transfer the test images\n",
    "    for image in test_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(test_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "else:\n",
    "    print(\"Data already exists (Hopefully), it might not be transfered correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e624c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Total:', len(os.listdir('train_dir/1'))+len(os.listdir('train_dir/0')))\n",
    "print('Valid Total:', len(os.listdir('val_dir/1'))+len(os.listdir('val_dir/0')))\n",
    "print('Test Total:', len(os.listdir('test_dir/1'))+len(os.listdir('test_dir/0')), '\\n')\n",
    "\n",
    "print('Train Negative:', len(os.listdir('train_dir/0')))\n",
    "print('Train Positive:', len(os.listdir('train_dir/1')), '\\n')\n",
    "\n",
    "print('Valid Negative:', len(os.listdir('val_dir/0')))\n",
    "print('Valid Positive:', len(os.listdir('val_dir/1')), '\\n')\n",
    "\n",
    "print('Test Negative:', len(os.listdir('test_dir/0')))\n",
    "print('Test Positive:', len(os.listdir('test_dir/1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663aa84",
   "metadata": {},
   "source": [
    "# Agumentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create temporary directories here and delete these directories later\n",
    "aug_dir = 'aug_dir'\n",
    "os.mkdir(aug_dir)\n",
    "# create a dir within the base dir to store images of the same class\n",
    "img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "os.mkdir(img_dir)\n",
    "\n",
    "# list all images in that directory\n",
    "img_list = os.listdir('train_dir/1')\n",
    "\n",
    "# copy images from the class all images directory to the image directory\n",
    "for fname in img_list:\n",
    "    # source path to image\n",
    "    src = os.path.join('train_dir/1', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(img_dir, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "# point to a dir containing the images and not to the images themselves\n",
    "path = 'aug_dir'\n",
    "save_path = 'train_dir/1'\n",
    "\n",
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.125,\n",
    "    height_shift_range=0.125,\n",
    "    zoom_range=[1.2, 1.325],\n",
    "    fill_mode='reflect')\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "aug_datagen = datagen.flow_from_directory(path,\n",
    "                                          save_to_dir=save_path,\n",
    "                                          save_format='jpg',\n",
    "                                          target_size=(image_size, image_size),\n",
    "                                          batch_size=batch_size)\n",
    "\n",
    "# generate the augmented images and add them to the folder of all images\n",
    "\n",
    "num_aug_images_wanted = len(os.listdir('train_dir/0')) # total number of images wanted in each class\n",
    "\n",
    "num_files = len(os.listdir(img_dir))\n",
    "num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "for i in range(0, num_batches):\n",
    "  next(aug_datagen)\n",
    "\n",
    "# delete temporary directory with the raw image files\n",
    "shutil.rmtree('aug_dir')\n",
    "\n",
    "\n",
    "# Check how many train images we have in each folder\n",
    "\n",
    "print('Train Total:', len(os.listdir('train_dir/1'))+len(os.listdir('train_dir/0')))\n",
    "print('Train Positive:', len(os.listdir('train_dir/1')))\n",
    "print('Train Negative:', len(os.listdir('train_dir/0')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9fc63",
   "metadata": {},
   "source": [
    "### Create train / test / validation batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_path = 'train_dir_AUG'\n",
    "valid_path = 'val_dir_AUG'\n",
    "test_path = 'test_dir_AUG'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "\n",
    "train_batch_size = 500\n",
    "val_batch_size = 500\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ee74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=keras.applications.inception_v3.preprocess_input, \n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "image_size=100\n",
    "\n",
    "train_batches_bench = datagen.flow_from_directory(train_path, \n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=train_batch_size)\n",
    "\n",
    "valid_batches_bench = datagen.flow_from_directory(valid_path,  \n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=val_batch_size)\n",
    "\n",
    "test_batches_bench = datagen.flow_from_directory(test_path,  \n",
    "                                                 target_size=(image_size, image_size),\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=False) # test dataset should not be shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a0c50",
   "metadata": {},
   "source": [
    "## Train Baseline Model (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "vgg = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(244, 244, 3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f138bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb300ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(vgg.output)  # One flatten layer\n",
    "prediction = tf.keras.layers.Dense(2, activation='softmax')(x) # one softmax layer\n",
    "model = tf.keras.Model(inputs=vgg.input, outputs=prediction)   # Final Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ae18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be checked\n",
    "# We need to know which data to be added exactly. We want the Image Data Generator function but without any agumentation (for now)\n",
    "# did not have time to check exactly how. \n",
    "# Try to compare with the paper stuff. Hopefully we will be able to find something.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(filepath='breast_histopathology_baseline_AUG.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "class_weights={\n",
    "    0: 1.0, # negative\n",
    "    1: 1.0, # postive \n",
    "    # make model more sensitive to positive class if necessary\n",
    "}\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy']) \n",
    "history = model.fit(train_batches_bench, \n",
    "                                            steps_per_epoch=train_steps, \n",
    "                                            class_weight=class_weights,\n",
    "                                            validation_data=valid_batches_bench,\n",
    "                                            validation_steps=val_steps,\n",
    "                                            callbacks=[model_checkpoint], \n",
    "                                            epochs=30, \n",
    "                                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epoch_count = range(1, 31)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, val_acc, 'b-')\n",
    "plt.legend(['Training Acc', 'Validation Acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig(\"../vgg19-baseline-model-AUG.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Weights of the Baseline Model\n",
    "model.load_weights('breast_histopathology_baseline_AUG.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b87bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Predictions\n",
    "preds = model.predict_generator(test_batches_bench, steps=len(df_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45973f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy using the baseline model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# Take the highest probability scores to get index of predictions for test images\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "# Get labels of test images\n",
    "y_true = test_batches_bench.classes\n",
    "\n",
    "# Evaluate\n",
    "print(f'Accuracy: {accuracy_score(y_true, y_pred):1.3f}%')\n",
    "\n",
    "print(f'Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred):1.3f}%')\n",
    "# Balanced accuracy is calculated as the average of the proportion correct of each class individually\n",
    "\n",
    "f = open(\"../testOutput_AUG.txt\", \"w\")\n",
    "f.write(f'Accuracy: {accuracy_score(y_true, y_pred):1.3f}%\\n')\n",
    "f.write(f'Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred):1.3f}%\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for the baseline model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap='viridis')\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(['negative', 'positive']))\n",
    "plt.xticks(tick_marks, ['negative', 'positive'])\n",
    "plt.yticks(tick_marks, ['negative', 'positive'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../vgg19-baseline-model-confusion-matrix-AUG.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d207314",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "f = open(\"../testOutput_AUG.txt\", \"a\")\n",
    "f.write(f'Confusion matrix: {confusionmatrix}\\n')\n",
    "f.close()\n",
    "\n",
    "confusionmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true=y_true, y_pred=y_pred, target_names=['negative', 'positive'])\n",
    "\n",
    "f = open(\"../testOutput_AUG.txt\", \"a\")\n",
    "f.write(f'REPORT:\\n {report}\\n')\n",
    "f.close()\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_batches_bench.next()\n",
    "\n",
    "for i in range(1,10):\n",
    "  \n",
    "  image = x[i]\n",
    "  label = y[i]\n",
    "  f = open(\"../testOutput_AUG.txt\", \"a\")\n",
    "  if np.argmax(label, axis=0) == 0:\n",
    "      print('IDC negative')\n",
    "      f.write(f'IDC negative\\n')\n",
    "  if np.argmax(label, axis=0) == 1:\n",
    "    print('IDC positive')\n",
    "    f.write(f'IDC positive\\n')\n",
    "\n",
    "#   print(image.shape)\n",
    "#   prob = model.predict(image)\n",
    "#   for a in prob:\n",
    "#     for b in a:\n",
    "#       print(f'Predicted Negative Probability: {(b*100):1.2f}%')\n",
    "#       print(f'Predicted Positive Probability: {(1-b)*100:1.2f}%')\n",
    "#       f.write(f'Predicted Negative Probability: {(b*100):1.2f}%\\n')\n",
    "#       f.write(f'Predicted Positive Probability: {(1-b)*100:1.2f}%\\n')\n",
    "#       break\n",
    "\n",
    "  plt.imshow(image)\n",
    "#   f.write(image)\n",
    "  plt.show()\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca26e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
