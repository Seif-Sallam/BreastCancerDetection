{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing that the machine recognizes the GPU\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from os.path import isfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import utils\n",
    "import itertools\n",
    "import shutil\n",
    "np.random.seed(42)\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to get rid of changing the directory more than once\n",
    "os.chdir(current_dir)\n",
    "\n",
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "all_images_dir = 'all_images_dir_NOAUG'\n",
    "os.chdir('./breast-histopathology-images/')\n",
    "# copies all images from their seperate folders into the same \n",
    "# folder called all_images_dir\n",
    "\n",
    "\n",
    "# create a list of all patient id's\n",
    "# each patient id folder has 2 sub folders --> folder 0 and folder 1\n",
    "\n",
    "# Example:\n",
    "    # '10285'\n",
    "        # '0'\n",
    "        # '1'\n",
    "    \n",
    "all_pos_len = len(os.listdir(f'{all_images_dir}/1'))\n",
    "all_neg_len = len(os.listdir(f'{all_images_dir}/0'))\n",
    "\n",
    "\n",
    "if all_pos_len == 0 or all_neg_len == 0:\n",
    "    cur_dir = os.getcwd()\n",
    "    patient_list = os.listdir(cur_dir)\n",
    "\n",
    "    for patient in patient_list:\n",
    "\n",
    "      try:\n",
    "\n",
    "        path_0 = str(patient) + '/0'\n",
    "        path_1 = str(patient) + '/1'\n",
    "\n",
    "        # create a list of all files in folder 0\n",
    "        file_list_0 = os.listdir(path_0)\n",
    "        # create a list of list all file in folder 1\n",
    "        file_list_1 = os.listdir(path_1)\n",
    "\n",
    "        # move the 0 images to all_images_dir\n",
    "        for fname in file_list_0:\n",
    "\n",
    "            # source path to image\n",
    "            src = os.path.join(path_0, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(all_images_dir, '0', fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "        # move the 1 images to all_images_dir\n",
    "        for fname in file_list_1:\n",
    "\n",
    "            # source path to image\n",
    "            src = os.path.join(path_1, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(all_images_dir, '1', fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "      except:\n",
    "         print(patient, 'cannot be copied into proper folder')\n",
    "else:\n",
    "    print(\"Data already exists. Skipped copying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many images are in each folder, to make sure we have correct data\n",
    "print('Total:', all_pos_len + all_neg_len)\n",
    "print('Positive:', all_pos_len)\n",
    "print('Negative:', all_neg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "# Create a dataframe containing all the information\n",
    "\n",
    "image_list_1 = os.listdir(f'{all_images_dir}/1')\n",
    "df_data_1 = pd.DataFrame(image_list_1, columns=['image_id'])\n",
    "\n",
    "image_list_0 = os.listdir(f'{all_images_dir}/0')\n",
    "df_data_0 = pd.DataFrame(image_list_0, columns=['image_id'])\n",
    "\n",
    "df_data = pd.concat([df_data_1, df_data_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating that the data now exists in the dataframe\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Mostly, taken from the other author's notebook. ######\n",
    "\n",
    "# Define Helper Functions\n",
    "\n",
    "# Each file name has this format:\n",
    "# '14211_idx5_x2401_y1301_class1.png'\n",
    "\n",
    "def extract_patient_id(x):\n",
    "    # split into a list\n",
    "    a = x.split('_')\n",
    "    # the id is the first index in the list\n",
    "    patient_id = a[0]\n",
    "    \n",
    "    return patient_id\n",
    "\n",
    "def extract_target(x):\n",
    "    # split into a list\n",
    "    a = x.split('_')\n",
    "    # the target is part of the string in index 4\n",
    "    b = a[4]\n",
    "    # the ytarget i.e. 1 or 2 is the 5th index of the string --> class1\n",
    "    target = b[5]\n",
    "    \n",
    "    return target\n",
    "\n",
    "# extract the patient id\n",
    "\n",
    "# create a new column called 'patient_id'\n",
    "df_data['patient_id'] = df_data['image_id'].apply(extract_patient_id)\n",
    "# create a new column called 'target'\n",
    "df_data['target'] = df_data['image_id'].apply(extract_target)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the class distribution of the dataset, We find that the negative is way more than the positives.\n",
    "sns.countplot(x=df_data.target).set_title(\"Class Distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_data['target']\n",
    "\n",
    "_, df_test = train_test_split(df_data, test_size=0.03603, random_state=42, stratify=y)\n",
    "\n",
    "_, df_val = train_test_split(df_data, test_size=0.0036025, random_state=42, stratify=y)\n",
    "\n",
    "print('Valid:', df_val.shape[0])\n",
    "print('Test:', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_val['target']).set_title('Valid Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_test['target']).set_title('Test Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved the speed of the identification through using a dictionary... Dramatically.\n",
    "val_dict = df_val.set_index('image_id').T.to_dict('list')\n",
    "test_dict = df_test.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "def identify_train_val_and_test_rows(x):\n",
    "    if str(x) in val_dict:\n",
    "        return 'val'\n",
    "    elif str(x) in test_dict:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_data['train_or_val_or_test'] = df_data['image_id']\n",
    "# apply the function to this new column\n",
    "df_data['train_or_val_or_test'] = df_data['train_or_val_or_test'].apply(identify_train_val_and_test_rows)\n",
    "   \n",
    "# filter out train rows\n",
    "df_train = df_data[df_data['train_or_val_or_test'] == 'train']\n",
    "\n",
    "print('Train:', len(df_train))\n",
    "print('Valid:', len(df_val))\n",
    "print('Test:', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_train['target']).set_title('Train Class Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image_id as the index in df_data\n",
    "df_data.set_index('image_id', inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Train, Valid, and Test Folders\n",
    "\n",
    "\n",
    "# Create folders within the train, valid, and test folders\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# train_dir\n",
    "train_dir = os.path.join(\"train_dir_NOAUG\")\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    # create new folders inside train_dir\n",
    "    os.mkdir(os.path.join(train_dir, '1'))\n",
    "    os.mkdir(os.path.join(train_dir, '0'))\n",
    "    \n",
    "# val_dir\n",
    "val_dir = os.path.join('val_dir_NOAUG')\n",
    "if not os.path.isdir(val_dir):\n",
    "    os.mkdir(val_dir)\n",
    "    # Create new folders inside val_dir\n",
    "    os.mkdir(os.path.join(val_dir, '1'))\n",
    "    os.mkdir(os.path.join(val_dir, '0'))\n",
    "\n",
    "# test_dir\n",
    "test_dir = os.path.join('test_dir_NOAUG')\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    # Create new folders inside test_dir\n",
    "    os.mkdir(os.path.join(test_dir, '1'))\n",
    "    os.mkdir(os.path.join(test_dir, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfering the data from the starting directory to the training directory\n",
    "if len(os.listdir(train_dir)) == 0:\n",
    "    # Get a dict of train, val, and test images\n",
    "    train_dict = df_train.set_index('image_id').T.to_dict('list')\n",
    "    test_dict = df_test.set_index('image_id').T.to_dict('list')\n",
    "    val_dict = df_val.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "    # Transfer the train images\n",
    "    for image in train_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # Transfer the val images\n",
    "    for image in val_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # Transfer the test images\n",
    "    for image in test_dict:\n",
    "        pat_id = df_data.loc[image,'patient_id']\n",
    "        label = df_data.loc[image,'target']\n",
    "        src = pat_id + '/' + label + '/' + image\n",
    "\n",
    "        # destination path to image\n",
    "        dst = os.path.join(test_dir, label, image)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "else:\n",
    "    print(\"Data already exists (Hopefully), it might not be transfered correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that all the data there is correctly numbered. We should have the same number AND CORRECT data\n",
    "print('Train Total:', len(os.listdir('train_dir_NOAUG/1'))+len(os.listdir('train_dir_NOAUG/0')))\n",
    "print('Valid Total:', len(os.listdir('val_dir_NOAUG/1'))+len(os.listdir('val_dir_NOAUG/0')))\n",
    "print('Test Total:', len(os.listdir('test_dir_NOAUG/1'))+len(os.listdir('test_dir_NOAUG/0')), '\\n')\n",
    "\n",
    "print('Train Negative:', len(os.listdir('train_dir_NOAUG/0')))\n",
    "print('Train Positive:', len(os.listdir('train_dir_NOAUG/1')), '\\n')\n",
    "\n",
    "print('Valid Negative:', len(os.listdir('val_dir_NOAUG/0')))\n",
    "print('Valid Positive:', len(os.listdir('val_dir_NOAUG/1')), '\\n')\n",
    "\n",
    "print('Test Negative:', len(os.listdir('test_dir_NOAUG/0')))\n",
    "print('Test Positive:', len(os.listdir('test_dir_NOAUG/1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_path = 'train_dir_NOAUG'\n",
    "valid_path = 'val_dir_NOAUG'\n",
    "test_path = 'test_dir_NOAUG'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "\n",
    "train_batch_size = 500\n",
    "val_batch_size = 500\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=keras.applications.inception_v3.preprocess_input, \n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "image_size=100\n",
    "\n",
    "train_batches_bench = datagen.flow_from_directory(train_path, \n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=train_batch_size)\n",
    "\n",
    "valid_batches_bench = datagen.flow_from_directory(valid_path,  \n",
    "                                                  target_size=(image_size, image_size),\n",
    "                                                  batch_size=val_batch_size)\n",
    "\n",
    "test_batches_bench = datagen.flow_from_directory(test_path,  \n",
    "                                                 target_size=(image_size, image_size),\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=False) # test dataset should not be shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "vgg = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\t\t\t# We do not want the classifier on top of the VGG19, we will use our own classifier\n",
    "    weights='imagenet',\t\t\t# We want the imagenet weights\n",
    "    input_shape=(image_size, image_size, 3)\t# The input shape is 100, 100, 3 (RGB)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the model have untrainale layers\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(vgg.output)  # One flatten layer\n",
    "prediction = tf.keras.layers.Dense(2, activation='softmax')(x) # one softmax layer\n",
    "model = tf.keras.Model(inputs=vgg.input, outputs=prediction)   # Final Model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be checked\n",
    "# We need to know which data to be added exactly. We want the Image Data Generator function but without any agumentation (for now)\n",
    "# did not have time to check exactly how. \n",
    "# Try to compare with the paper stuff. Hopefully we will be able to find something.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint(filepath='breast_histopathology_baseline_NOAUG.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "class_weights={\n",
    "    0: 1.0, # negative\n",
    "    1: 1.0, # postive \n",
    "    # make model more sensitive to positive class if necessary\n",
    "}\n",
    "\n",
    "# using RMSProp optimizer as it  is the best optimizers according to this paper:\n",
    "# https://www.sciencedirect.com/science/article/pii/S2214785321013316\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['accuracy']) \n",
    "history = model.fit(train_batches_bench, \n",
    "\t\t\t\t\tsteps_per_epoch=train_steps, \n",
    "\t\t\t\t\tclass_weight=class_weights,\n",
    "\t\t\t\t\tvalidation_data=valid_batches_bench,\n",
    "\t\t\t\t\tvalidation_steps=val_steps,\n",
    "\t\t\t\t\tcallbacks=[model_checkpoint], \n",
    "\t\t\t\t\tepochs=30, \n",
    "\t\t\t\t\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epoch_count = range(1, 31)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, val_acc, 'b-')\n",
    "plt.legend(['Training Acc', 'Validation Acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig(\"../vgg19_baseline_model_NOAUG.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
